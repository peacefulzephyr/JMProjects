{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages & Path\n",
    "# pip install pdfplumber\n",
    "import os\n",
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "dir = os.path.join(os.getcwd(), \"SADC All\") # Folder containing all pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Indexing function using regex\n",
    "def substringindex(inputlist, inputsubstring):\n",
    "    '''\n",
    "    Identify the 1st substring in list of strings\n",
    "    Return (index, string)\n",
    "    '''\n",
    "    s = [x for x in inputlist if re.search(inputsubstring, x)]\n",
    "\n",
    "    if s != []:\n",
    "        return (inputlist.index(s[0]), s[0])\n",
    "    return 'Unidentified'\n",
    "\n",
    "def substringindex2(inputlist, inputsubstring):\n",
    "    '''\n",
    "    Identify the 2nd substring in list of strings\n",
    "    Return (index, string)\n",
    "    '''\n",
    "    s = [x for x in inputlist if re.search(inputsubstring, x)]\n",
    "\n",
    "    if s != []:\n",
    "        return (inputlist.index(s[1]), s[1])\n",
    "    return 'Unidentified'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Extraction Function\n",
    "def pdfextract_report(inputfilename):\n",
    "    '''\n",
    "    Extracts Info from PDFs\n",
    "    Input: File name (without directory info); directory should be specified in advance\n",
    "    Returns: A list of filename, Company_Name, Country, Sector, ReportDate\n",
    "    '''\n",
    "    inputfilepath = os.path.join(dir, inputfilename) \n",
    "    with pdfplumber.open(inputfilepath) as pdf:\n",
    "        page1 = pdf.pages[0].extract_text() # Only page 1 will be used\n",
    "\n",
    "        # Extract Company Name\n",
    "        lines = page1.split('\\n') # Split page1 into various lines\n",
    "        filter1 = filter(lambda x: x.strip(), lines) # Remove empty string elements\n",
    "        lines_clean = list(filter1)                 # Remove empty string elements\n",
    "\n",
    "        Company_Name = lines_clean[0].strip() # Company name is always the first non-empty line\n",
    "\n",
    "        # Extract Country, Sector, ReportDate\n",
    "        try:\n",
    "            if substringindex(lines_clean,'Analysis') == 'Unidentified': # Get the 1st string element with 'Analysis' in it\n",
    "                Country = ''\n",
    "                Sector = ''\n",
    "                ReportDate = ''\n",
    "            else: \n",
    "                Country_Sector_Date = substringindex(lines_clean,'Analysis')[1].split(\" Analysis \") # Create a list of [Company+Sector, Date]\n",
    "                Country_Sector = Country_Sector_Date[0].strip() # Create a list of [Company+Sector, Date]\n",
    "                Country = Country_Sector.rsplit(' ', 1)[0].strip() # Country is the first part of Company_Sector\n",
    "                Sector = Country_Sector.rsplit(' ', 1)[1].strip() # Sector is the second part of Company_Sector\n",
    "                ReportDate = Country_Sector_Date[1].strip() # Report is the 2nd element of list Country_Sector_Date\n",
    "        except:\n",
    "            Country = ''\n",
    "            Sector = ''\n",
    "            ReportDate = ''\n",
    "\n",
    "\n",
    "        # Extract Long-term Rating Info\n",
    "        try:\n",
    "            if substringindex(lines_clean,'Long') == 'Unidentified':\n",
    "                RatingInfo = ''\n",
    "            else: \n",
    "                RatingInfo = substringindex(lines_clean,'Long')[1]     # Long-term rating info is the first string element with 'Long'\n",
    "        except:\n",
    "            RatingInfo = ''\n",
    "\n",
    "        # Extract Outlook & Expiry Date\n",
    "        try: \n",
    "            list_of_outlook_expirydate_raw = substringindex2(lines_clean, '(\\d){4}')[1].strip().split(' ')  # Outlook & Expiry Dates might not be in the long term rating row, so they'd better to be extracted separately\n",
    "            Outlook_Expirydate = [x for x in list_of_outlook_expirydate_raw if x][-3:] # Take the last 4 nonempty items from the string containing Outlook & Exp Dates\n",
    "            Outlook = ' '.join(Outlook_Expirydate[:-2])\n",
    "            ExpirydateMonth = Outlook_Expirydate[-2]\n",
    "            ExpirydateYear = Outlook_Expirydate[-1]\n",
    "        except:\n",
    "            Outlook = ''\n",
    "            ExpirydateMonth = ''\n",
    "            ExpirydateYear = ''\n",
    "\n",
    "        # Extract Financial Year Dates\n",
    "        try: \n",
    "            FYs_raw = substringindex(lines_clean, '(\\d){2}/(\\d){2}/(\\d){2}')[1].strip().split(' ') # Financial Year dates are the first string element containing pattern 12/34/56\n",
    "            FYs = [x for x in FYs_raw if x] # Remove empty strings ('') from list \n",
    "            FY1 = FYs[0]\n",
    "            FY2 = FYs[1]\n",
    "        except:\n",
    "            FY1 = ''\n",
    "            FY2 = ''\n",
    "        \n",
    "        # Extract Total Assets\n",
    "        try:\n",
    "            TotalAssets_Raw = substringindex(lines_clean, 'Total assets')[1].strip() \n",
    "            TotalAssets_Clean = re.sub(\"(?<=\\d) (?=\\d)\", \",\", TotalAssets_Raw).split(' ') # Remove spaces between two numbers - important since there are assets larger than 999 denoted by '1 234' instead of '1,234'\n",
    "            TotalAssets = [x for x in TotalAssets_Clean if x] # Remove empty strings ('') from list \n",
    "            TotalAssets1 = TotalAssets[2]\n",
    "            TotalAssets2 = TotalAssets[3]\n",
    "        except:\n",
    "            TotalAssets1 = ''\n",
    "            TotalAssets2 = ''\n",
    "        \n",
    "        # Extract Rating Histories\n",
    "        try:\n",
    "            InitialDate = substringindex(lines_clean, 'Initial')[1] \n",
    "            lines_below = lines_clean[substringindex(lines_clean, 'Initial')[0]+1:] # List of all lines below 'Initial Date'\n",
    "            InitialRating = substringindex(lines_below, 'Long-term|Long term')[1] # Initial Long-term rating \n",
    "            try:\n",
    "                LastDate = substringindex(lines_below, 'Last')[1] # The first occurence of 'Last' in the lines below 'Initial Date'\n",
    "                lines_below2 = lines_below[substringindex(lines_below, 'Last')[0]+1:] # List of all lines below 'Last Date' \n",
    "                LastRating = substringindex(lines_below2, 'Long-term|Long term')[1] # Last Long-term rating\n",
    "            except:\n",
    "                LastDate = ''\n",
    "                LastRating = ''\n",
    "        except:\n",
    "            InitialDate = ''\n",
    "            InitialRating = ''\n",
    "            LastDate = ''\n",
    "            LastRating = ''\n",
    "\n",
    "        # Extract Primary Analyst\n",
    "        try:\n",
    "            GCRContacts = lines_clean[substringindex(lines_clean, 'Primary Analyst')[0]+1:] # Subset lines in the 'GCR Contacts' section\n",
    "            PrimaryAnalyst = substringindex(GCRContacts, '[A-Z][a-z]+\\s[A-Z][a-z]+')[1] # Look for full name pattern: Azzzz Zaa\n",
    "            PrimaryAnalystEmail = substringindex(GCRContacts, '@globalratings.net')[1] \n",
    "            PrimaryAnalystPosition_raw = GCRContacts[substringindex(GCRContacts, '[A-Z][a-z]+\\s[A-Z][a-z]+')[0]+1:substringindex(GCRContacts, '@globalratings.net')[0]] # Subset a list between [PA name] and [PA email] - should contain [PA position]]\n",
    "            PrimaryAnalystPosition = substringindex(PrimaryAnalystPosition_raw, 'Analyst|Head')[1] # All positions I've seen have 'Analyst' or 'Head' in there - needs further cleaning\n",
    "        except:\n",
    "            PrimaryAnalyst = ''\n",
    "            PrimaryAnalystEmail = ''\n",
    "            PrimaryAnalystPosition = ''\n",
    "\n",
    "        # Extract Committee Chairperson\n",
    "        try:\n",
    "            GCRContacts_afterPA = lines_clean[substringindex(lines_clean, 'Committee Chairperson')[0]+1:] # The method is exactly the same as the PA section above\n",
    "\n",
    "            CommitteeChairperson = substringindex(GCRContacts_afterPA, '[A-Z][a-z]+\\s[A-Z][a-z]+')[1] \n",
    "            CommitteeChairpersonEmail = substringindex(GCRContacts_afterPA, '@globalratings.net')[1]\n",
    "            CommitteeChairpersonPosition_raw = GCRContacts_afterPA[substringindex(GCRContacts_afterPA, '[A-Z][a-z]+\\s[A-Z][a-z]+')[0]+1:substringindex(GCRContacts_afterPA, '@globalratings.net')[0]]\n",
    "            CommitteeChairpersonPosition = substringindex(CommitteeChairpersonPosition_raw, 'Analyst|Head')[1]\n",
    "        except:\n",
    "            CommitteeChairperson = ''\n",
    "            CommitteeChairpersonEmail = ''\n",
    "            CommitteeChairpersonPosition = ''\n",
    "\n",
    "        # Extract Tel\n",
    "        try:\n",
    "            Tel_raw = substringindex(lines_clean, 'Tel:')[1]\n",
    "            Tel = re.sub('[^0-9\\+\\-]', '', Tel_raw) # Tel only has number, '+' and/or '-'\n",
    "        except:\n",
    "            Tel = ''\n",
    "\n",
    "        # Extract Analyst location:\n",
    "        try:\n",
    "            ALoc_raw = substringindex(lines_clean, 'Analyst location')[1].split('Analyst location')[-1]\n",
    "            ALoc = re.sub('[^A-z\\,\\s]', '', ALoc_raw).strip() # Location has only Alphabet, ',', and/or space\n",
    "        except:\n",
    "            ALoc = ''\n",
    "\n",
    "        return (inputfilename, Company_Name, Country, Sector, ReportDate, RatingInfo, Outlook, ExpirydateMonth, ExpirydateYear, FY1, FY2, TotalAssets1, TotalAssets2, InitialDate, InitialRating, LastDate,LastRating, PrimaryAnalyst, PrimaryAnalystPosition , PrimaryAnalystEmail, CommitteeChairperson, CommitteeChairpersonPosition ,CommitteeChairpersonEmail, Tel, ALoc )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "\n",
    "# Create Dataframe \n",
    "df = pd.DataFrame(columns = ['Filename', 'Company_Name', 'Country', 'Sector', 'Report_Date', 'RatingInfo', 'Outlook', 'ExpirydateMonth', 'ExpirydateYear', 'FY1', 'FY2','TotalAssets1','TotalAssets2', 'InitialDate', 'InitialRating', 'LastDate','LastRating', 'PrimaryAnalyst', 'PrimaryAnalystPosition' , 'PrimaryAnalystEmail', 'CommitteeChairperson', 'CommitteeChairpersonPosition' ,'CommitteeChairpersonEmail', 'Tel', 'Analyst_Location'])\n",
    "\n",
    "# Code to Loop through all files\n",
    "row = 0 # Record current row info\n",
    "success = 0 # Record the current number of successful extracts\n",
    "skipped = 0 # Record number of files skipped because the format is not supported\n",
    "total_N = len(os.listdir(dir)) # Record the total number of files in the directory\n",
    "\n",
    "for pdf in os.listdir(dir):\n",
    "    # Sending Message\n",
    "    if pdf.endswith('.pdf'): # Only extract PDF files\n",
    "        print('Extracting', pdf, ' ; ', row + 1, '/', total_N) # Signal that file is being extracted, and the current progress\n",
    "\n",
    "        # Filtering single format\n",
    "        try:\n",
    "            try:\n",
    "                df.loc[row] = pdfextract_report(pdf) # Append the info from the pdf to df as a new line\n",
    "                success += 1\n",
    "            except:\n",
    "                print(\"***Error: file\", pdf)\n",
    "                df.loc[row] = [pdf] + ['']*(df.shape[1]-1) # If there's an error, append a new line to df with only filename\n",
    "\n",
    "            row = row + 1\n",
    "        except:\n",
    "            print('*Warning: file skipped - format not supported', pdf)\n",
    "            skipped += 1\n",
    "\n",
    "print('Extraction Complete')\n",
    "print('Success:', success, '; total: ', row,  '; skipped: ', skipped)\n",
    "\n",
    "# Output Dataframe\n",
    "df.to_csv(dir+' output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2e8110911ba48ca806f83175925361660178792222adaad95582d1a80031ef9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
